import os
import sys
from pathlib import Path
import pandas as pd
from sqlalchemy import create_engine, text
from sqlalchemy.exc import SQLAlchemyError
from dotenv import load_dotenv
from pathlib import Path

# ----------------------
# ç’°å¢ƒè®Šæ•¸èˆ‡å…¨åŸŸè¨­å®š
# ----------------------

env_path = Path(__file__).parent / ".env"
load_dotenv(dotenv_path=env_path, override=True, encoding="utf-8") or load_dotenv(find_dotenv(), override=True, encoding="utf-8")

# ä¿®æ­£å¯èƒ½å­˜åœ¨çš„ BOM éµå
for k in list(os.environ.keys()):
    if k.startswith("\ufeff"):
        os.environ[k.lstrip("\ufeff")] = os.environ.pop(k)

DB_URL = os.getenv("DB_URL", "").strip()
if not DB_URL:
    pg_host = os.getenv("PG_HOST", "localhost")
    pg_port = os.getenv("PG_PORT", "5432")
    pg_db   = os.getenv("PG_DB", "postgres")
    pg_user = os.getenv("PG_USER", "postgres")
    pg_pwd  = os.getenv("PG_PASSWORD", "")
    DB_URL = f"postgresql+psycopg2://{pg_user}:{pg_pwd}@{pg_host}:{pg_port}/{pg_db}"


EXCEL_PATH = os.getenv(
    "EXCEL_PATH",
    "C:/Users/admin/Desktop/info/side_project/English_retail/data/online_retail_II.xlsx",
).strip()
SHEETS_ENV = os.getenv("SHEETS", "Year 2009-2010,Year 2010-2011").strip()

DAILY_REVENUE_MIN = float(os.getenv("DAILY_REVENUE_MIN", "1000"))
DAILY_REVENUE_MAX = float(os.getenv("DAILY_REVENUE_MAX", "5000000"))
MISSING_CUST_MAX = float(os.getenv("MISSING_CUSTOMER_ID_MAX_RATIO", "0.1"))

SLACK_WEBHOOK_URL = os.getenv("SLACK_WEBHOOK_URL", "").strip()
ALERT_EMAIL_FROM = os.getenv("ALERT_EMAIL_FROM", "").strip()
ALERT_EMAIL_TO = os.getenv("ALERT_EMAIL_TO", "").strip()
SMTP_HOST = os.getenv("SMTP_HOST", "").strip()
SMTP_PORT = int(os.getenv("SMTP_PORT", "587"))
SMTP_USER = os.getenv("SMTP_USER", "").strip()
SMTP_PASS = os.getenv("SMTP_PASS", "").strip()

SCHEMA_NAME = os.getenv("SCHEMA_NAME", "etl").strip()

def _engine():
    """å»ºç«‹ SQLAlchemy engineï¼ˆé€£ç·šéŒ¯èª¤çµ¦å‡ºæ¸…æ¥šæç¤ºï¼‰"""
    if not DB_URL:
        raise RuntimeError(
            "DB_URL æœªè¨­å®šã€‚è«‹åœ¨ .env æˆ–ç³»çµ±ç’°å¢ƒè®Šæ•¸ä¸­è¨­å®šï¼Œä¾‹å¦‚ï¼š\n"
            "DB_URL=postgresql+psycopg2://postgres:YOUR_PASSWORD@localhost:5432/mydb"
        )
    try:
        eng = create_engine(DB_URL, pool_pre_ping=True)
        # ç°¡å–®æ¸¬è©¦é€£ç·š
        with eng.connect() as conn:
            conn.execute(text("SELECT 1"))
        return eng
    except SQLAlchemyError as e:
        raise RuntimeError(f"ç„¡æ³•é€£ç·šåˆ°è³‡æ–™åº«ï¼Œè«‹æª¢æŸ¥ DB_URLã€‚è©³æƒ…ï¼š{e}")


# ----------------------
# E (Extract)
# ----------------------
def extract_data() -> pd.DataFrame:
    """
    è®€å– Excel -> å›å‚³åˆä½µå¾Œçš„ DataFrame
    - SHEETS æŒ‡å®šè¦è®€çš„å·¥ä½œè¡¨ï¼Œé€—è™Ÿåˆ†éš”ï¼›è‹¥ç‚ºç©ºå­—ä¸²ï¼Œå‰‡è®€å…¨éƒ¨ sheet
    """
    excel_path = Path(EXCEL_PATH)
    if not excel_path.exists():
        raise FileNotFoundError(
            f"æ‰¾ä¸åˆ° Excel æª”æ¡ˆï¼š{excel_path}\n"
            "è«‹ç¢ºèª EXCEL_PATH æ˜¯å¦æ­£ç¢ºï¼Œæˆ–å°‡æª”æ¡ˆæ”¾åœ¨è©²è·¯å¾‘ã€‚"
        )

    print(f"ğŸ“¥ è®€å– Excelï¼š{excel_path}")
    # è§£æ SHEETSï¼ˆå…è¨±ç©ºï¼Œç©º=å…¨è®€ï¼‰
    sheets = [s.strip() for s in SHEETS_ENV.split(",") if s.strip()]
    # è®€å–
    if sheets:
        frames = []
        for s in sheets:
            print(f"  - è®€å– sheet: {s}")
            df = pd.read_excel(excel_path, sheet_name=s, engine="openpyxl")
            df["source_sheet"] = s
            frames.append(df)
        raw = pd.concat(frames, ignore_index=True)
    else:
        # å…¨éƒ¨ sheet
        xls = pd.ExcelFile(excel_path, engine="openpyxl")
        frames = []
        for s in xls.sheet_names:
            print(f"  - è®€å– sheet: {s}")
            df = pd.read_excel(xls, sheet_name=s)
            df["source_sheet"] = s
            frames.append(df)
        raw = pd.concat(frames, ignore_index=True)

    print(f"ğŸ“¦ æ“·å–å®Œæˆï¼š{len(raw):,} åˆ—")
    return raw


# ----------------------
# T (Transform)
# ----------------------
def transform_data(df: pd.DataFrame) -> pd.DataFrame:
    """
    æ¬„ä½æ¨™æº–åŒ– + å‹åˆ¥è½‰æ› + è¨ˆç®— total_amount + é€€è²¨è¾¨è­˜ + year_month
    """
    print("ğŸ§ª é€²è¡Œè½‰æ›èˆ‡æ¸…ç† ...")
    # ä¾†æºè³‡æ–™ä¸ä¸€è‡´æ™‚çš„ä¸€äº›å¸¸è¦‹æ¬„ä½åå°æ‡‰
    rename_candidates = {
        "Invoice": "invoice",
        "InvoiceNo": "invoice",
        "StockCode": "stock_code",
        "Description": "description",
        "Quantity": "quantity",
        "InvoiceDate": "invoice_date",
        "Price": "unit_price",
        "UnitPrice": "unit_price",
        "Customer ID": "customer_id",
        "CustomerID": "customer_id",
        "Country": "country",
    }
    # å¯¬é¬†æ¯”å°ï¼ˆå»é¦–å°¾ç©ºç™½ï¼‰
    df = df.rename(columns={k: v for k, v in rename_candidates.items() if k in df.columns})

    # ç¢ºä¿å¿…è¦æ¬„ä½å­˜åœ¨
    required = ["invoice", "stock_code", "description", "quantity", "invoice_date", "unit_price", "country"]
    missing = [c for c in required if c not in df.columns]
    if missing:
        raise ValueError(f"ç¼ºå°‘å¿…è¦æ¬„ä½ï¼š{missing}\nè«‹ç¢ºèªåŸå§‹æª”çš„æ¬„ä½åç¨±èˆ‡ SHEETS æ˜¯å¦æ­£ç¢ºã€‚")

    # å‹åˆ¥è™•ç†
    df["invoice_date"] = pd.to_datetime(df["invoice_date"], errors="coerce")
    df["quantity"] = pd.to_numeric(df["quantity"], errors="coerce")
    df["unit_price"] = pd.to_numeric(df["unit_price"], errors="coerce")
    if "customer_id" in df.columns:
        df["customer_id"] = df["customer_id"].astype("string")
    else:
        df["customer_id"] = pd.Series(pd.NA, dtype="string")

    df["stock_code"] = df["stock_code"].astype("string")
    df["description"] = df["description"].astype("string").str.strip()

    # è¨ˆç®—é‡‘é¡
    df["total_amount"] = df["quantity"].fillna(0) * df["unit_price"].fillna(0)

    # é€€è²¨è¾¨è­˜ï¼šInvoice ä»¥ C é–‹é ­ æˆ– æ•¸é‡ < 0
    df["is_return"] = df["invoice"].astype(str).str.startswith("C") | (df["quantity"] < 0)

    # å¹´æœˆï¼ˆå­—ä¸²ï¼‰
    df["year_month"] = df["invoice_date"].dt.to_period("M").astype(str)

    # åŸºæœ¬è¡Œæ•¸æ‘˜è¦
    n_null_date = int(df["invoice_date"].isna().sum())
    n_returns = int(df["is_return"].sum())
    print(f"ğŸ§® è½‰æ›å®Œæˆï¼š{len(df):,} åˆ—ï½œç©ºæ—¥æœŸ {n_null_date:,} åˆ—ï½œé€€è²¨ {n_returns:,} åˆ—")
    return df


# ----------------------
# L (Load)
# ----------------------
def load_data(df: pd.DataFrame):
    """å¯«é€² PostgreSQLï¼šstaging + cleanedï¼ˆæ’é™¤é€€è²¨ã€è² æ•¸/å–®åƒ¹<=0ï¼‰"""
    print("ğŸ’¾ è¼‰å…¥è³‡æ–™åˆ° PostgreSQL ...")
    eng = _engine()
    with eng.begin() as conn:
        df.to_sql("sales_staging", conn, if_exists="replace", index=False, schema=SCHEMA_NAME)

        cleaned = df.loc[
            (~df["is_return"]) &
            (df["quantity"].fillna(0) >= 0) &
            (df["unit_price"].fillna(0) > 0)
        ].copy()

        cleaned.to_sql("sales_cleaned", conn, if_exists="replace", index=False, schema=SCHEMA_NAME)
        print(f"âœ… å¯«å…¥å®Œæˆï¼š{SCHEMA_NAME}.sales_staging={len(df):,} åˆ—, {SCHEMA_NAME}.sales_cleaned={len(cleaned):,} åˆ—")


# ----------------------
# é€šçŸ¥ï¼ˆé¸æ“‡æ€§åŸ·è¡Œï¼‰
# ----------------------
def _send_slack(msg: str):
    if not SLACK_WEBHOOK_URL:
        return
    try:
        import requests  # è¼•é‡ç›¸ä¾ï¼Œæœªè¨­å®šå°±ä¸ç™¼
        requests.post(SLACK_WEBHOOK_URL, json={"text": msg}, timeout=10)
    except Exception as e:
        print(f"Slack send failed: {e}")


def _send_email(msg: str):
    if not (ALERT_EMAIL_FROM and ALERT_EMAIL_TO and SMTP_HOST and SMTP_USER and SMTP_PASS):
        return
    try:
        import smtplib
        from email.mime.text import MIMEText

        m = MIMEText(msg, "plain", "utf-8")
        m["Subject"] = "ETL Data Quality Alert"
        m["From"] = ALERT_EMAIL_FROM
        m["To"] = ALERT_EMAIL_TO
        with smtplib.SMTP(SMTP_HOST, SMTP_PORT) as s:
            s.starttls()
            s.login(SMTP_USER, SMTP_PASS)
            s.send_message(m)
    except Exception as e:
        print(f"Email send failed: {e}")


# ----------------------
# DQï¼ˆæ¯æ—¥ç›£æ§ï¼‰
# ----------------------
def quality_check():
    """
    æ¯æ—¥ DQï¼šç•¶æ—¥éŠ·å”®ç¸½é¡ã€ç¼ºå¤± customer_id æ¯”ä¾‹ï¼›ç•°å¸¸å‰‡è­¦ç¤ºä¸¦è¨˜éŒ„åˆ° dq_monitor_log
    """
    print("ğŸ” åŸ·è¡Œæ¯æ—¥ DQ æª¢æŸ¥ ...")
    eng = _engine()
    with eng.begin() as conn:
        # è‹¥è¡¨ä¸å­˜åœ¨ï¼Œç›´æ¥çµ¦æç¤ºä¸¦è¿”å›ï¼ˆé¿å…ç¬¬ä¸€æ¬¡å°±å ±éŒ¯ï¼‰
        exists = conn.execute(
            text(
                """
                SELECT to_regclass('public.sales_cleaned') IS NOT NULL AS exists_cleaned
                """
            )
        ).scalar()
        if not exists:
            print("â„¹ï¸ å°šæœªæ‰¾åˆ°è¡¨ 'sales_cleaned'ï¼Œè«‹å…ˆåŸ·è¡Œ ETL è¼‰å…¥ã€‚ç•¥é DQã€‚")
            return

        q = """
            SELECT
                COALESCE(SUM(total_amount), 0) AS daily_total,
                AVG(CASE WHEN customer_id IS NULL OR customer_id = '' THEN 1.0 ELSE 0.0 END) AS missing_ratio
            FROM sales_cleaned
            WHERE invoice_date::date = CURRENT_DATE
        """
        row = conn.execute(text(q)).mappings().first() or {}
        daily_total = float(row.get("daily_total") or 0.0)
        missing_ratio = float(row.get("missing_ratio") or 0.0)

        status = "PASS"
        alerts = []
        if not (DAILY_REVENUE_MIN <= daily_total <= DAILY_REVENUE_MAX):
            alerts.append(
                f"daily_total={daily_total:,.2f} out of range [{DAILY_REVENUE_MIN:,.0f},{DAILY_REVENUE_MAX:,.0f}]"
            )
        if missing_ratio > MISSING_CUST_MAX:
            alerts.append(
                f"missing_customer_id_ratio={missing_ratio:.2%} > {MISSING_CUST_MAX:.2%}"
            )

        if alerts:
            status = "FAIL"
            msg = "âš ï¸ DQ Alert: " + " | ".join(alerts)
            print(msg)
            _send_slack(msg)
            _send_email(msg)
        else:
            print(
                f"âœ… DQ OK: daily_total={daily_total:,.2f}, missing_ratio={missing_ratio:.2%}"
            )

        # å¯«å…¥ç›£æ§è¡¨ï¼ˆè‹¥ä¸å­˜åœ¨å‰‡å»ºç«‹ï¼‰
        conn.execute(
            text(
                """
                CREATE TABLE IF NOT EXISTS dq_monitor_log (
                  check_ts TIMESTAMP DEFAULT NOW(),
                  check_date DATE,
                  daily_total NUMERIC,
                  missing_customer_ratio NUMERIC,
                  status TEXT,
                  alert_message TEXT
                );
                """
            )
        )
        conn.execute(
            text(
                """
                INSERT INTO dq_monitor_log (check_date, daily_total, missing_customer_ratio, status, alert_message)
                VALUES (CURRENT_DATE, :t, :r, :s, :m)
                """
            ),
            {"t": daily_total, "r": missing_ratio, "s": status, "m": " | ".join(alerts)},
        )
        print("ğŸ“ å·²å¯«å…¥ dq_monitor_log")


# ----------------------
# å¯é¸ï¼šæœ¬æª”å–®ç¨åŸ·è¡Œæ™‚çš„å¿«é€Ÿæ¸¬è©¦
# ----------------------
if __name__ == "__main__":
    try:
        df_raw = extract_data()
        df_tr = transform_data(df_raw)
        load_data(df_tr)
        quality_check()
        print("ğŸ‰ å–®æª”æ¸¬è©¦å®Œæˆ")
    except Exception as e:
        print(f"âŒ ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")
        sys.exit(1)